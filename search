import requests
from bs4 import BeautifulSoup
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
import json

def search_news_ZDG (company_name):
    data = []
    search_url = f"https://www.zdg.md/?s={company_name.replace(' ','+')}"
    print(search_url)

    # Setăm un mecanism de reîncercare pentru a evita MaxRetryError
    session = requests.Session()
    retry = Retry(connect=5, backoff_factor=0.5)
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('https://', adapter)
    session.mount('http://', adapter)

    try:
        response = session.get(search_url)
        response.raise_for_status()  # Ridicăm o excepție dacă codul statusului HTTP nu este 200 OK
        yc_web_page = response.text
        print(yc_web_page)

        soup = BeautifulSoup(response.text, 'html.parser')
        div_media_simple = soup.find('div', class_="media__simple")
        if div_media_simple:
            articles = div_media_simple.find_all('article')
            print(articles)
            articles_list = [{'article_html': str(article)} for article in articles]
            with open('articles_list.json', 'w') as file:
                json.dump(articles_list, file, indent=4)

    except requests.RequestException as e:
        print("A apărut o eroare de rețea:", e)
    except Exception as e:
        print("A apărut o eroare:", e)


# search_news_ZDG("Gemenii")

# --------------------------------!!!!!!!!!!!!!!!!!!!!!--------------------------------------
def search_news_Anticoruptie(company_name):
    data = []
    search_url = f"https://anticoruptie.md/ro/search?word={company_name.replace(' ','+')}"

    print(search_url)

    # Setăm un mecanism de reîncercare pentru a evita MaxRetryError
    session = requests.Session()
    retry = Retry(connect=5, backoff_factor=0.5)
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('https://', adapter)
    session.mount('http://', adapter)
    print(1)

    try:
        response = session.get(search_url)
        response.raise_for_status()  # Ridicăm o excepție dacă codul statusului HTTP nu este 200 OK
        soup = BeautifulSoup(response.text, 'html.parser')
        check_element = soup.find('div', class_='arhiv-title').find_all('p')[1].contents[0].strip()
        print(check_element)

        if check_element == "0 rezultate ":
            print("Nu a fost gasit nici un articold despre: ", company_name)

        else:
            articles = soup.find_all('div', class_="arhiv-box jan")
            print(articles)
            articles_list = [{'article_html': str(article)} for article in articles]
            with open('articles_list.json', 'w') as file:
                json.dump(articles_list, file, indent=4)

    except requests.RequestException as e:
        print("A apărut o eroare de rețea:", e)
    except Exception as e:
        print("A apărut o eroare:", e)

search_news_Anticoruptie("SA TUTUN-CTC")
