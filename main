import urllib3
from bs4 import BeautifulSoup
import ssl
import requests
import json
import re


def search_news():
    urllib3.disable_warnings()
    http = urllib3.PoolManager(cert_reqs=ssl.CERT_NONE)

    try:
        response = http.request('GET', 'https://anticoruptie.md')
        yc_web_page = response.data  # Extracting HTML content from the response
        print(yc_web_page)
        soup = BeautifulSoup(yc_web_page, "html.parser")
        articles = soup.find_all('div', class_="col-md-17")  # You may need to adjust this class name
        print(articles)
    except Exception as e:
        print("Error occurred:", e)


def search_news_2():
    response = requests.get("https://anticoruptie.md/ro/search?word=Gemenii", verify=False)
    yc_web_page = response.text
    print(yc_web_page)
    soup = BeautifulSoup(yc_web_page, "html.parser")
    articles = soup.find_all('div', class_="col-md-17")
    print(articles)

def extract_form_json():
    with open(r"C:\Users\Marin.M.Mucuta\PycharmProjects\PycharmProjects\Parsing_News\articles_list.json", 'r') as f:
        data = json.load(f)

    # Iterate over each entry in the JSON
    for entry in data:
        # Extract relevant information from the HTML code
        article_html = entry['article_html']
        try:
            title = re.search(r'<span class="inner-title">(.*?)</span>', article_html).group(1)
            url = re.search(r'href="(.*?)"', article_html).group(1)
            date = re.search(r'<span class="date-timestamp">(.*?)</span>', article_html).group(1)

            print("Title:", title)
            print("URL:", url)
            print("Date:", date)
            print()

        except AttributeError:
            print("Failed to extract inf from article.\n")





# article_texts = []
# article_links = []
# for article_tag in articles:
#     text = article_tag.getText()
#     article_texts.append(text)
#     link = article_tag.get("href")
#     article_links.append(link)
#
# # article_upvotes = [int(score.getText().split()[0]) for score in soup.find_all(name="span", class_="score")]
# #
# # largest_number = max(article_upvotes)
# # largest_index = article_upvotes.index(largest_number)
#
# print(article_texts)
# print(article_links)
# search_news()
search_news_2()
# extract_form_json()

